\subsection*{Contents}


\begin{DoxyEnumerate}
\item \href{https://github.com/nathancharlesjones/Look-up-Table-Examples/blob/master/02_Other-Sin-Improvements/README.md#what-is-it}{\tt What is it?}
\item \href{https://github.com/nathancharlesjones/Look-up-Table-Examples/blob/master/02_Other-Sin-Improvements/README.md#whats-it-telling-me}{\tt What\textquotesingle{}s it telling me?}
\item \href{https://github.com/nathancharlesjones/Look-up-Table-Examples/blob/master/02_Other-Sin-Improvements/README.md#how-do-i-use-it}{\tt How do I use it?}
\item \href{https://github.com/nathancharlesjones/Look-up-Table-Examples/blob/master/02_Other-Sin-Improvements/README.md#how-does-it-work}{\tt How does it work?}
\end{DoxyEnumerate}

\subsection*{What is it?}

\char`\"{}\+Other Sin Improvements\char`\"{} builds on the demonstration in \char`\"{}01\+\_\+\+Fast-\/\+Sin\char`\"{} of using a simple look-\/up table (L\+UT) to improve the execution time of the library sin function. These L\+UT examples add different data types, linear interpolation, and arbitrary-\/input tables in order to improve the execution time, accuracy, or memory size of the L\+UT in \char`\"{}01\+\_\+\+Fast-\/\+Sin\char`\"{}. It also profiles and compares to the L\+UT implementations four different implementations of \char`\"{}sin\char`\"{} that utilize various polynomial approximations. Lastly, it builds upon the the professional quality code from \char`\"{}01\+\_\+\+Fast-\/\+Sin\char`\"{} by parameterizing the test code (to more easily change which functions are being tested).

The following table summarizes the results, though it should be noted that all of the L\+U\+Ts could be made larger/smaller and more/less accurate by simply increasing or decreasing the number of elements in the table (though care should be taken to ensure that the resulting size allows for a quick and simple hash function, as execution time may be negatively affected if the hash becomes non-\/trivial). This code was compiled for an S\+T\+M32\+F1 running at 72 M\+Hz using G\+CC 6.\+3.\+1 on Ubuntu (there’s also code to run this same example on an x86 so you don’t need an S\+T\+M32\+F1 in order to test it, though the results are less drastic). The rest of this R\+E\+A\+D\+ME should explain each part of the table, so don\textquotesingle{}t fret if parts of it don\textquotesingle{}t make sense at this time. \tabulinesep=1mm
\begin{longtabu} spread 0pt [c]{*{5}{|X[-1]}|}
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Function}&\textbf{ Memory usage\textsuperscript{1} (bytes)}&\textbf{ Max Absolute Error}&\textbf{ Percent Error}&\textbf{ Execution time  }\\\cline{1-5}
\endfirsthead
\hline
\endfoot
\hline
\rowcolor{\tableheadbgcolor}\textbf{ Function}&\textbf{ Memory usage\textsuperscript{1} (bytes)}&\textbf{ Max Absolute Error}&\textbf{ Percent Error}&\textbf{ Execution time  }\\\cline{1-5}
\endhead
Library sin&5480&N/A&N/A&47 us \\\cline{1-5}
L\+UT double\textsuperscript{3}&3484\textsuperscript{2}&0.\+0076\textsuperscript{2}&2.\+5\textsuperscript{1}&6.\+7 us \\\cline{1-5}
L\+UT float\textsuperscript{4}&2736\textsuperscript{2}&0.\+0076\textsuperscript{2}&1.\+5\textsuperscript{1}&6.\+4 us \\\cline{1-5}
L\+UT fixed\textsuperscript{5}&1808\textsuperscript{2}&0.\+0077\textsuperscript{2}&1.\+6\textsuperscript{1}&0.\+73 us \\\cline{1-5}
L\+UT fixed (safe)\textsuperscript{6}&2060\textsuperscript{2}&0.\+0077\textsuperscript{2}&1.\+5\textsuperscript{1}&1.\+3 us \\\cline{1-5}
Dbl interp\textsuperscript{7}&3548\textsuperscript{2}&0.\+00003\textsuperscript{2}&0.\+002\textsuperscript{1}&13.\+9 us \\\cline{1-5}
Flt interp\textsuperscript{8}&2848\textsuperscript{2}&0.\+00003\textsuperscript{2}&0.\+002\textsuperscript{1}&9.\+9 us \\\cline{1-5}
Fxd interp\textsuperscript{9}&1840\textsuperscript{2}&0.\+00003\textsuperscript{2}&0.\+002\textsuperscript{1}&1.\+0 us \\\cline{1-5}
Fxd interp (safe)\textsuperscript{10}&2284\textsuperscript{2}&0.\+00003\textsuperscript{2}&0.\+002\textsuperscript{1}&2.\+6 us \\\cline{1-5}
Dbl Non-\/\+Uni\textsuperscript{11}&824\textsuperscript{2}&0.\+007\textsuperscript{2}&0.\+62\textsuperscript{1}&40.\+9 us \\\cline{1-5}
Flt Non-\/\+Uni\textsuperscript{12}&1432\textsuperscript{2}&0.\+007\textsuperscript{2}&0.\+63\textsuperscript{1}&25.\+8 us \\\cline{1-5}
Fxd Non-\/\+Uni\textsuperscript{13}&1376\textsuperscript{2}&0.\+007\textsuperscript{2}&0.\+61\textsuperscript{1}&6.\+5 us \\\cline{1-5}
Fxd Non-\/\+Uni (safe)\textsuperscript{14}&1916\textsuperscript{2}&0.\+007\textsuperscript{2}&0.\+61\textsuperscript{1}&8.\+8 us \\\cline{1-5}
Sin\+\_\+32\textsuperscript{15}&2128&0.\+0006&0.\+44&19.\+7 us \\\cline{1-5}
Sin\+\_\+52\textsuperscript{16}&2144&0.\+000007&0.\+0016&22.\+0 us \\\cline{1-5}
Sin\+\_\+73\textsuperscript{17}&1280&0.\+00000005&0.\+00002&28.\+1 us \\\cline{1-5}
Sin\+\_\+121\textsuperscript{18}&1344&0.\+0000000000007&0.\+0000000006&35.\+1 us \\\cline{1-5}
\end{longtabu}
\subsubsection*{Notes\+:}


\begin{DoxyEnumerate}
\item Memory usage was measured very non-\/academically, by observing the difference in the output of the {\ttfamily size} tool with each function included and them removed. In particular, I wasn\textquotesingle{}t sure if certain external library functions such as type conversions were included when I didn\textquotesingle{}t want them to be. It seems possible to glean this information from the map file. I\textquotesingle{}d love to hear any better suggestions!
\item This L\+UT could be made larger/smaller and more/less accurate by simply increasing or decreasing the number of elements in the table (though care should be taken to ensure that the resulting size allows for a quick and simple hash function, as execution time may be negatively affected if the hash becomes non-\/trivial).
\item \char`\"{}\+L\+U\+T double\char`\"{} is a L\+UT of doubles with uniform distribution which uses no interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+L\+U\+T float\char`\"{} is a L\+UT of floats with uniform distribution which uses no interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+L\+U\+T fixed\char`\"{} is a L\+UT of fixed-\/point numbers (in q0\+\_\+31 format) with uniform distribution which uses no interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+L\+U\+T fixed (safe)\char`\"{} is a L\+UT of fixed-\/point numbers (in q0\+\_\+31 format) with uniform distribution which uses no interpolation. It includes checks for integer overflow, which \char`\"{}\+L\+U\+T fixed\char`\"{} does not. It was stored in R\+AM in my tests.
\item \char`\"{}\+Dbl interp\char`\"{} is a L\+UT of doubles with uniform distribution which uses linear interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+Flt interp\char`\"{} is a L\+UT of floats with uniform distribution which uses linear interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+Fxd interp\char`\"{} is a L\+UT of fixed-\/point numbers (in q0\+\_\+31 format) with uniform distribution which uses linear interpolation. It was stored in R\+AM in my tests.
\item \char`\"{}\+Fxd interp (safe)\char`\"{} is a L\+UT of fixed-\/point numbers (in q0\+\_\+31 format) with uniform distribution which uses linear interpolation. It includes checks for integer overflow, which \char`\"{}\+Fxd interp\char`\"{} does not. It was stored in R\+AM in my tests.
\item \char`\"{}\+Dbl Non-\/\+Uni\char`\"{} is a L\+UT of doubles with non-\/uniform distribution which uses linear interpolation. It was stored in R\+OM in my tests.
\item \char`\"{}\+Flt Non-\/\+Uni\char`\"{} is a L\+UT of floats with non-\/uniform distribution which uses linear interpolation. It was stored in R\+OM in my tests.
\item \char`\"{}\+Fxd Non-\/\+Uni\char`\"{} is a L\+UT of fixed-\/point numbers (x-\/vales in q9\+\_\+22 format and y-\/values in q0\+\_\+31 format) with non-\/uniform distribution which uses linear interpolation. It was stored in R\+OM in my tests.
\item \char`\"{}\+Fxd Non-\/\+Uni (safe)\char`\"{} is a L\+UT of fixed-\/point numbers (x-\/vales in q9\+\_\+22 format and y-\/values in q0\+\_\+31 format) with non-\/uniform distribution which uses linear interpolation. It includes checks for integer overflow, which \char`\"{}\+Fxd Non-\/\+Uni\char`\"{} does not. It was stored in R\+OM in my tests.
\item \char`\"{}\+Sin\+\_\+32\char`\"{} is a polynomial approximation of sin which uses 3 terms. For more information, see \href{http://www.ganssle.com/approx.htm}{\tt here}.
\item \char`\"{}\+Sin\+\_\+52\char`\"{} is a polynomial approximation of sin which uses 4 terms. For more information, see \href{http://www.ganssle.com/approx.htm}{\tt here}.
\item \char`\"{}\+Sin\+\_\+73\char`\"{} is a polynomial approximation of sin which uses 5 terms. For more information, see \href{http://www.ganssle.com/approx.htm}{\tt here}.
\item \char`\"{}\+Sin\+\_\+121\char`\"{} is a polynomial approximation of sin which uses 7 terms. For more information, see \href{http://www.ganssle.com/approx.htm}{\tt here}.
\end{DoxyEnumerate}

\subsection*{What\textquotesingle{}s it telling me?}


\begin{DoxyItemize}
\item L\+U\+Ts can greatly improve both execution time (up to 64 times faster in my tests with the \char`\"{}sin\char`\"{} function) and memory space (down to nearly 1/7 the size of the \char`\"{}sin\char`\"{} function in my tests) at the cost of accuracy (and it\textquotesingle{}s not really possible to have all three).
\item To improve a L\+UT\textquotesingle{}s execution time\+:
\begin{DoxyItemize}
\item Use data types that take advantage of whatever processor the code is running on (e.\+g. use fixed-\/point numbers on a processor without a floating-\/point unit, use 32-\/bit data types for 32-\/bit processors, etc).
\item Simplify and/or remove both the hash (the part of the code that converts the input into an appropriate array index) and any post-\/processing (such as linear interpolation); revert from a non-\/uniform distribution of x-\/values to a uniform distribution. (If accuracy is a concern, you could add more points to your L\+UT.)
\end{DoxyItemize}
\item To improve a L\+UT\textquotesingle{}s accuracy\+:
\begin{DoxyItemize}
\item Add linear interpolation of points (or use a non-\/uniform distribution of x-\/values).
\item Add more points to the L\+UT.
\item Move to higher precision data types (i.\+e. from fixed-\/point number to floats to doubles).
\end{DoxyItemize}
\item To improve a L\+UT\textquotesingle{}s memory space\+:
\begin{DoxyItemize}
\item Change to a smaller data type (i.\+e. from doubles to floats or fixed-\/point numbers).
\item Use a non-\/uniform distribution of x-\/values.
\item Remove points from the L\+UT (keep conversions in mind (i.\+e. powers-\/of-\/two multiplication); speed reductions could be significant if they aren\textquotesingle{}t).
\end{DoxyItemize}
\end{DoxyItemize}

\subsection*{How do I use it?}

\subsubsection*{On my laptop}


\begin{DoxyEnumerate}
\item After downloading the Git repo, navigate to the folder \char`\"{}02\+\_\+\+Other-\/\+Sin-\/\+Improvements\char`\"{}.
\item Decide whether you want a \char`\"{}debug\char`\"{} or \char`\"{}release\char`\"{} build (the only difference being which optimization flag is passed to the compiler\+: \char`\"{}-\/\+Og\char`\"{} in the case of a \char`\"{}debug\char`\"{} build and \char`\"{}-\/\+O2\char`\"{} in the case of a release build) and type {\ttfamily make B\+U\+I\+LD=\{debug or release\} T\+A\+R\+G\+ET=x86} into a shell (replacing \char`\"{}\{debug or release\}\char`\"{} with either \char`\"{}debug\char`\"{} or \char`\"{}release\char`\"{}, of course). E.\+g.\+: 
\begin{DoxyCode}
$ make BUILD=debug TARGET=x86
\end{DoxyCode}

\item The executable is called \char`\"{}\{debug or release\}\textbackslash{}\+\_\+x86.\+elf\char`\"{} and it will be placed in a folder called \char`\"{}build/\{debug or release\}\textbackslash{}\+\_\+x86\char`\"{}.
\item Run the executable; the results of the code will be printed to the terminal. \char`\"{}\+Scaffolding\char`\"{} runs the profiling code with no function call; it informs us how much of the \char`\"{}average execution time\char`\"{} reported for every other function is taken up by the \char`\"{}scaffolding\char`\"{} code, such as storing the start and end times in their respective variables and asserting that there were no errors in doing so. To get the adjusted (i.\+e. correct) values for each function\textquotesingle{}s execution time, I would think that we should simply be able to subtract off the execution time for \char`\"{}scaffolding\char`\"{}, however, doing that with the numbers below doesn\textquotesingle{}t make much sense. My best guess is that my laptop is performing optimizations as the code is running so that functions further down on the list execute faster than earlier ones. E.\+g.\+: 
\begin{DoxyCode}
$ ./build/debug\_x86/debug.elf 
-----Sin LUT Test-----
Number of iterations: 1000

Function        Avg Exec Time (ns)  Max Abs Err     Avg Abs Err     Avg Pcnt Err
------------------------------------------------------------------------------------
Scaffolding     1400.669000         0.999999631059  0.652310682314  100.000000000000
Library Sin     1461.493000         0.000000000000  0.000000000000  0.000000000000
LUT Double      1368.243000         0.007731751814  0.002422178446  1.741621087140
LUT Float       1477.782000         0.007781785917  0.002449251424  1.908848834801
LUT Fxd Pt      518.283000          0.007789333234  0.002425126663  1.745504007445
Dbl Interp      458.890000          0.000030399625  0.000013219860  0.002068185136
Flt Interp      491.998000          0.000030497550  0.000012931535  0.002032499788
Fxd Interp      480.742000          0.000030458810  0.000012775540  0.002012521111
Dbl X/Y list    480.910000          0.006942981122  0.003651405452  0.631011883711
Flt X/Y list    484.509000          0.006941808730  0.003474547855  0.613417469977
Fxd X/Y list    487.844000          0.006942964109  0.003529551882  0.608958238201
Sin\_32          467.824000          0.000596918907  0.000385646151  0.584851163968
Sin\_52          470.245000          0.000007009045  0.000004331988  0.001958647318
Sin\_73          485.269000          0.000000046536  0.000000029727  0.000014366719
Sin\_121         472.147000          0.000000000001  0.000000000000  0.000000000667
\end{DoxyCode}

\item Run {\ttfamily make B\+U\+I\+LD=\{debug or release\} T\+A\+R\+G\+ET=x86 clean} to remove the \char`\"{}build/\{debug or release\}\textbackslash{}\+\_\+x86\char`\"{} folder. E.\+g.\+: 
\begin{DoxyCode}
$ make BUILD=debug TARGET=x86 clean
\end{DoxyCode}

\end{DoxyEnumerate}

\subsubsection*{On an S\+T\+M32}


\begin{DoxyEnumerate}
\item Procure an S\+T\+M32\+F103\+C8\+T6, sometimes called a \char`\"{}\+Blue Pill\char`\"{}.
\item After downloading the Git repo, navigate to the folder \char`\"{}02\+\_\+\+Other-\/\+Sin-\/\+Improvements\char`\"{}.
\end{DoxyEnumerate}
\begin{DoxyEnumerate}
\item Decide whether you want a \char`\"{}debug\char`\"{} or \char`\"{}release\char`\"{} build (the only difference which optimization flag is passed to the compiler\+: \char`\"{}-\/\+Og\char`\"{} in the case of a \char`\"{}debug\char`\"{} build and \char`\"{}-\/\+O2\char`\"{} in the case of a release build) and type {\ttfamily make B\+U\+I\+LD=\{debug or release\} T\+A\+R\+G\+ET=S\+T\+M32\+F1} into a shell (replacing \char`\"{}\{debug or release\}\char`\"{} with either \char`\"{}debug\char`\"{} or \char`\"{}release\char`\"{}, of course). E.\+g.\+: 
\begin{DoxyCode}
$ make BUILD=debug TARGET=STM32F1
\end{DoxyCode}

\item The executable is called \char`\"{}\{debug or release\}\textbackslash{}\+\_\+\+S\+T\+M32\+F1.\+elf\char`\"{} and it will be placed in a folder called \char`\"{}build/\{debug or release\}\textbackslash{}\+\_\+\+S\+T\+M32\+F1\char`\"{}.
\item Connect your S\+T\+M32\+F1 to your computer using your debugger of choice (e.\+g. S\+T-\/\+Link, J-\/\+Link, etc) and start a G\+DB server. If you have previously downloaded S\+T\+M32\+Cube\+I\+DE, you can start a G\+DB server from the command line using the script \char`\"{}\+Start-\/\+S\+T-\/\+Link-\/\+G\+D\+B-\/\+Server\+\_\+v2.\+sh\char`\"{} (after updating the file paths appropriately). E.\+g.\+: 
\begin{DoxyCode}
$ ./Start-ST-Link-GDB-Server\_v2.sh
\end{DoxyCode}

\item Start G\+DB and then connect to your S\+T\+M32. E.\+g.\+: 
\begin{DoxyCode}
$ arm-none-eabi-gdb build/debug\_STM32F1/debug.elf --tui
(gdb) target remote :61234
\end{DoxyCode}

\item Load and run the executable. E.\+g.\+: 
\begin{DoxyCode}
(gdb) load build/debug\_STM32F1/debug.elf
(gdb) c
\end{DoxyCode}

\item The debugger will halt inside the function {\ttfamily print\+Results\+\_\+\+C\+UT}. You\textquotesingle{}ll be able to view the same parameters as above by printing each array element from G\+DB (i.\+e. {\ttfamily p code\+Under\+Test\mbox{[}0\mbox{]}} prints the results of the first test). \char`\"{}\+Scaffolding\char`\"{} ({\ttfamily code\+Under\+Test\mbox{[}0\mbox{]}}) runs the profiling code with no function call; it informs us how much of the \char`\"{}average execution time\char`\"{} reported for every other function is taken up by the \char`\"{}scaffolding\char`\"{} code, such as storing the start and end times in their respective variables and asserting that there were no errors in doing so. To get the adjusted (i.\+e. correct) values for each function\textquotesingle{}s execution time, simply subtract off the execution time for \char`\"{}scaffolding\char`\"{}. E.\+g.\+: 
\begin{DoxyCode}
(gdb) c
Continuing.

Program received signal SIGTRAP, Trace/breakpoint trap.
0x08004112 in printResults\_CUT (iterations=1000, codeUnderTest=0x20004b18, 
    codeUnderTest@entry=0x20004b20) at hardware/source/STM32F1/source/STM32F1.c:296
296         HALT\_IF\_DEBUGGING();
(gdb) p codeUnderTest[1]
$1 = \{fcn\_name = 0x8004c1c "Library Sin", function\_enum = fcn\_dbl\_in\_dbl\_out, \{
    fcn\_double = 0x80001b5 <sin>, fcn\_float = 0x80001b5 <sin>, 
    fcn\_fixedPoint = 0x80001b5 <sin>\}, executionTime\_ns = 64903853, 
  executionTime\_ns\_avg = 64903.853000000003, absoluteError\_sum = 0, absoluteError\_avg = 0, 
  absoluteError\_max = 0, percentError\_sum = 0, percentError\_avg = 0\}
(gdb) p codeUnderTest[6]
$2 = \{fcn\_name = 0x8004c58 "Flt Interp", function\_enum = fcn\_flt\_in\_flt\_out, \{
    fcn\_double = 0x800370d <sin\_LUT\_float\_interpolate>, 
    fcn\_float = 0x800370d <sin\_LUT\_float\_interpolate>, 
    fcn\_fixedPoint = 0x800370d <sin\_LUT\_float\_interpolate>\}, executionTime\_ns = 27818984, 
  executionTime\_ns\_avg = 27818.984, absoluteError\_sum = 0.012910090567522466, 
  absoluteError\_avg = 1.2910090567522466e-05, absoluteError\_max = 3.0493971900802386e-05, 
  percentError\_sum = 2.093253463428784, percentError\_avg = 0.0020932534634287838\}
(gdb)
\end{DoxyCode}

\end{DoxyEnumerate}

For more information about how the Makefile works, see \href{https://github.com/nathancharlesjones/Generic-Makefile-based-Project-for-x86-and-STM32F1}{\tt here}.

\subsection*{How does it work?}

For the sake of brevity, I\textquotesingle{}ll not reiterate what was discussed in the \href{https://github.com/nathancharlesjones/Look-up-Table-Examples/blob/master/01_Fast-Sin/README.md#how-does-it-work}{\tt \char`\"{}\+How does it work?\char`\"{}} section of \char`\"{}01\+\_\+\+Fast-\/\+Sin\char`\"{} (which includes how to build a basic L\+UT; how to test for the average execution times, average absolute errors, and average percent error; and how to structure the project so that it can be compiled and run on both an x86 and S\+T\+M32\+F1 processor).

\subsubsection*{Parameterizing the tests}

Adding tests to or subtracting tests from the code in \char`\"{}01\+\_\+\+Fast-\/\+Sin\char`\"{} was already getting tedious, and with many more functions to add, I decided to first refactor {\ttfamily main} to make that easier. I wanted to make two major changes\+: (1) Put the variables that hold the profiling information for each function (e.\+g. {\ttfamily absolute\+Error\+\_\+avg}, {\ttfamily execution\+Time\+\_\+ns\+\_\+sum}, etc) into a struct for each function being tested (so that I don\textquotesingle{}t need to keep changing the input parameters to {\ttfamily print\+Results} every time I change which functions are being tested) and (2) Put a pointer to the functions being tested into that struct so that the profiling code (which doesn\textquotesingle{}t change) can be put in one spot and simply called multiple times with function pointers for each of the functions being tested.

To accomplish (1), I created a struct in {\ttfamily main.\+h} called {\ttfamily sin\+L\+U\+T\+\_\+implementation\+\_\+t} that included a {\ttfamily const char $\ast$} for the function name and several variables of type {\ttfamily double} to hold the various pieces of profiling information. Eventually, I could create different instances of {\ttfamily sin\+L\+U\+T\+\_\+implementation\+\_\+t} for each function being tested and then simply pass this array to {\ttfamily print\+Results} (which I renamed {\ttfamily print\+Results\+\_\+\+C\+UT}). I used an empty struct ({\ttfamily \{0\}}) to signal the end of the array. 
\begin{DoxyCode}
typedef struct sinLUT\_implementation\_t
\{
    const char * fcn\_name;
    ...
    double executionTime\_ns;
    double executionTime\_ns\_avg;
    double absoluteError\_sum;
    double absoluteError\_avg;
    double absoluteError\_max;
    double percentError\_sum;
    double percentError\_avg;
\} sinLUT\_implementation\_t;
\end{DoxyCode}
 On the surface, accomplishing (2) wasn\textquotesingle{}t awful either. However, the slightly complex part was getting the profiling code to work with different function pointers (that is, pointers to functions with different signatures). To start, I created three function typedefs in {\ttfamily sin\+\_\+lut.\+h} to represent my three main functions\+: {\ttfamily p\+\_\+sin\+\_\+\+L\+U\+T\+\_\+double}, {\ttfamily p\+\_\+sin\+\_\+\+L\+U\+T\+\_\+float}, and {\ttfamily p\+\_\+sin\+\_\+\+L\+U\+T\+\_\+fixed\+Point}, corresponding to each function\textquotesingle{}s input/output data types (I did not experiment with mixed data types, such as receiving a fixed-\/point input and returning a double). 
\begin{DoxyCode}
typedef double (*p\_sin\_LUT\_double)(double);
typedef float (*p\_sin\_LUT\_float)(float);
typedef q0\_31\_t (*p\_sin\_LUT\_fixedPoint)(q9\_22\_t);
\end{DoxyCode}
 I then added a function pointer to my new struct {\ttfamily sin\+L\+U\+T\+\_\+implementation\+\_\+t}, above. Since each function pointer is, effectively, a different data type, I put the three of them into a {\ttfamily union}. In this manner, the {\ttfamily sin\+L\+U\+T\+\_\+implementation\+\_\+t} struct would only store one of them at a time, and an enumerated data type called {\ttfamily fcn\+Signature\+\_\+t} (which I also added) would indicate which (if any) of the function pointers was active (for more about unions, see \href{https://www.tutorialspoint.com/cprogramming/c_unions.htm}{\tt here}, \href{https://www.geeksforgeeks.org/union-c/}{\tt here}, or \href{https://github.com/nathancharlesjones/Flexible-message-format}{\tt here}). 
\begin{DoxyCode}
typedef enum fcnSignature\_t
\{
    NOT\_ASSIGNED,
    fcn\_scaffolding,
    fcn\_dbl\_in\_dbl\_out,
    fcn\_flt\_in\_flt\_out,
    fcn\_fxd\_in\_fxd\_out
\} fcnSignature\_t;

typedef struct sinLUT\_implementation\_t
\{
    ...
    fcnSignature\_t function\_enum;
    union
    \{
        p\_sin\_LUT\_double fcn\_double;
        p\_sin\_LUT\_float fcn\_float;
        p\_sin\_LUT\_fixedPoint fcn\_fixedPoint;
    \};
    ...
\} sinLUT\_implementation\_t;
\end{DoxyCode}
 In {\ttfamily main}, now, we start by initializing the array of functions to test. Each function gets a name, a function type, a pointer to the function to call, and zeros for the profiling data. 
\begin{DoxyCode}
sinLUT\_implementation\_t codeUnderTest[] = 
\{
    \{ "Scaffolding",    fcn\_scaffolding,    \{.fcn\_double = NULL\},                               0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Library Sin",    fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\},                                0, 0, 0, 0,
       0, 0, 0 \},
    \{ "LUT Double",     fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\_LUT\_double\},                     0, 0, 0, 0,
       0, 0, 0 \},
    \{ "LUT Float",      fcn\_flt\_in\_flt\_out, \{.fcn\_float = sin\_LUT\_float\},                       0, 0, 0, 0,
       0, 0, 0 \},
    \{ "LUT Fxd Pt",     fcn\_fxd\_in\_fxd\_out, \{.fcn\_fixedPoint = sin\_LUT\_fixedPoint\},             0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Dbl Interp",     fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\_LUT\_double\_interpolate\},         0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Flt Interp",     fcn\_flt\_in\_flt\_out, \{.fcn\_float = sin\_LUT\_float\_interpolate\},           0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Fxd Interp",     fcn\_fxd\_in\_fxd\_out, \{.fcn\_fixedPoint = sin\_LUT\_fixedPoint\_interpolate\}, 0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Dbl X/Y list",   fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\_LUT\_double\_nonUniform\},          0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Flt X/Y list",   fcn\_flt\_in\_flt\_out, \{.fcn\_float = sin\_LUT\_float\_nonUniform\},            0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Fxd X/Y list",   fcn\_fxd\_in\_fxd\_out, \{.fcn\_fixedPoint = sin\_LUT\_fixedPoint\_nonUniform\},  0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Sin\_32\(\backslash\)t",       fcn\_flt\_in\_flt\_out, \{.fcn\_float = sin\_32\},                              0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Sin\_52\(\backslash\)t",       fcn\_flt\_in\_flt\_out, \{.fcn\_float = sin\_52\},                              0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Sin\_73\(\backslash\)t",       fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\_73\},                             0, 0, 0, 0,
       0, 0, 0 \},
    \{ "Sin\_121\(\backslash\)t",      fcn\_dbl\_in\_dbl\_out, \{.fcn\_double = sin\_121\},                            0, 0, 0, 0,
       0, 0, 0 \},
    \{0\}
\};
\end{DoxyCode}
 The profiling code was then restructured to be a {\ttfamily while} loop that iterates over the {\ttfamily code\+Under\+Test} array until the {\ttfamily N\+U\+LL} struct is found. For each function, the profiling code runs {\ttfamily test\+Iterations} numbers of loops, each time creating a new random input value, calling the function under test (while profiling it), and computing the errors. After all iterations, the average values are computed, the index variable is incremented, and the {\ttfamily while} loop continues. A {\ttfamily switch...case} statement in the body of the {\ttfamily for} loop decides which part of the union to access, based on which part is active (which is indicated by the {\ttfamily function\+\_\+enum} variable in the {\ttfamily sin\+L\+U\+T\+\_\+implementation\+\_\+t} struct). 
\begin{DoxyCode}
int idx\_CUT = 0;
    while( codeUnderTest[idx\_CUT].function\_enum != NOT\_ASSIGNED )
    \{
        for( int idx\_test = 0; idx\_test < testIterations; idx\_test++ )
        \{

            ...

            switch( codeUnderTest[idx\_CUT].function\_enum )
            \{
                case fcn\_scaffolding:
                    // Run profiling code
                break;

                case fcn\_dbl\_in\_dbl\_out:
                    // Run profiling code
                break;

                case fcn\_flt\_in\_flt\_out:
                    // Run profiling code
                break;

                case fcn\_fxd\_in\_fxd\_out:
                    // Run profiling code
                break;

                default:
                    ASSERT(0);
                // Unreachable
                break;
            \}           

            ...
        \}

        ...

        idx\_CUT++;
    \}
\end{DoxyCode}
 Adding new functions is now fairly trivial (provided they match one of the three function signatures used for the function pointers)\+: Simply write the function and then add an element to the {\ttfamily code\+Under\+Test} array with the appropriate information and the test will automatically get run. Removing a test is as simple as commenting out the line of code that puts it in the array.

\subsubsection*{Adding floats}

Changing the data type from doubles to floats involved no code changes, except to change {\ttfamily double} to {\ttfamily float}. The L\+UT could even stay the same, just being stored as floats instead of doubles, since the compiler would handle the actual conversion process. As expected, this resulted in a L\+UT that was half the size of one that used doubles. In each case tested, the resulting code had roughly the same accuracy as a L\+UT of doubles though the code ran anywhere from 4.\+7\% to 38\% faster.

\subsubsection*{Adding fixed-\/point numbers}

What\textquotesingle{}s a \char`\"{}fixed-\/point\char`\"{} number, you ask? Excellent question! Consider, first, an integer\+: the least significant bit of an integer has the value \char`\"{}1\char`\"{} (or 2\textsuperscript{0}), so 0b0001 is equal to \char`\"{}1\char`\"{} and 0b1001 is equal to \char`\"{}9\char`\"{}. There are no digits to the right of the lest significant bit, but what if there were? What would 0b0001.\+00 mean? If we extend the idea that the third bit of a binary number is 2\textsuperscript{3}, the second bit is 2\textsuperscript{2}, the first bit is 2\textsuperscript{1}, and the zeroth bit is 2\textsuperscript{0}, then the bit after the decimal (or \char`\"{}radix\char`\"{}) point might be 2\textsuperscript{-\/1} (or 0.\+5), then 2\textsuperscript{-\/2} (or 0.\+25), and so on. The digits to the left of the radix point become the \char`\"{}integer\char`\"{} bits and those to the right become the \char`\"{}fractional\char`\"{} bits. This is the meaning of a \char`\"{}fixed-\/point\char`\"{} number\+: an integer data type whose radix point is redefined to be somewhere other than to the right of the least significant bit. Assuming our example above of a fixed-\/point number is signed, \char`\"{}0b0001.\+00\char`\"{}, is said to be in \char`\"{}q3.\+2\char`\"{} format, meaning that there are 3 integer bits (plus an assumed sign bit) and 2 fractional bits. Instead of representing the range \mbox{[}-\/32, 31\mbox{]}, as it would if it were a plain signed integer, our example can now represent the range \mbox{[}-\/8, 7.\+75\mbox{]}, in increments of 0.\+25. For a 32-\/bit processor, such as the S\+T\+M32\+F1 we are using in these examples, it makes sense to make all fixed-\/point numbers 32-\/bits long and a commonly used format might be \char`\"{}q15.\+16\char`\"{}, allowing for a range of \mbox{[}-\/65536, 65535.\+999984741\mbox{]}, in increments of 1.\+5259e-\/5 (2\textsuperscript{-\/16}). For a processor without a floating-\/point unit, integer math (including operating on fixed-\/point numbers, since they are an \char`\"{}integer\char`\"{} data type, just with a different radix position) goes M\+U\+CH faster and doesn\textquotesingle{}t require additional code (as would be needed to perform floating-\/point math). For more information, see \href{https://developer.arm.com/documentation/dai0033/a/}{\tt here}.

I added the code at the above link into my project directly, adding two typedefs for the fixed-\/point data types I wanted to use. 
\begin{DoxyCode}
// Define a fixed-point type with 1 sign bit (implied), 0 integer bits, and 31 fractional bits
typedef int32\_t q0\_31\_t;

// Define a fixed-point type with 1 sign bit (implied), 9 integer bits, and 22 fractional bits
typedef int32\_t q9\_22\_t;
\end{DoxyCode}
 The first covers a range from \mbox{[}-\/1, 0.\+99999999976\mbox{]} in increments of 2.\+3283064e-\/10, perfect for representing the output values of our sin L\+U\+Ts. The second covers a range from \mbox{[}-\/512, 511.\+999999762\mbox{]} in increments of 2.\+38418579e-\/7; it\textquotesingle{}s used to represent the input values. Why is the integer portion so large if the input will only be as large as 2$\ast$\+PI? Because for two of the fixed-\/point L\+U\+Ts, the input is multiplied by 64 in order to get the array index and any fixed-\/point number with less than 9 integer bits could possible overflow, causing erroneous results.

Since multiplying and dividing fixed-\/point numbers changes the location of the radix point (see the link above for an explanation why), special operations are needed in order to preserve the position of the radix (or, more accurately, special operations are needed in order for the developer to specify what they want the final position of the radix to be). The code at that link provides these functions for us (such as {\ttfamily F\+D\+IV} and {\ttfamily F\+S\+U\+BG}), including a few that may seem redundant but which provide for a consistent interface (such as {\ttfamily F\+A\+DD} and {\ttfamily F\+M\+U\+LI}), as well as a few really useful operations ({\ttfamily T\+O\+F\+LT}, {\ttfamily T\+O\+F\+IX}, and {\ttfamily F\+C\+O\+NV}). These functions can (mostly) be used as direct stand-\/ins for the normal integer or floating-\/point operations in our L\+UT functions (i.\+e. {\ttfamily double x = radians $\ast$ 64} could be replaced with {\ttfamily q9\+\_\+22\+\_\+t x = F\+M\+U\+L\+I(radians, 64)}).

{\bfseries H\+O\+W\+E\+V\+ER}, I offer two points of caution when using fixed-\/point numbers\+:


\begin{DoxyEnumerate}
\item You are responsible for manually managing the various fixed-\/point data types you use in your program, which gets harder the more fixed-\/point data types you use. It was extremely easy while developing these examples for me to write some fixed-\/point code and only after I encounter a bug to realize that I hadn\textquotesingle{}t updated a single {\ttfamily q} argument which caused the result of a certain function to not come out in the q format that I had thought it would (i.\+e. I update a line like {\ttfamily q3\+\_\+28\+\_\+t x = F\+M\+U\+L\+G( a, b, 28, 22, 28);} to put {\ttfamily x} into {\ttfamily q9\+\_\+22\+\_\+t} format and change it to be {\ttfamily q9\+\_\+22\+\_\+t x = F\+M\+U\+L\+G( a, b, 28, 22, 28);}, forgetting that the fifth argument to {\ttfamily F\+M\+U\+LG} needs to match the q format of the output; the line should read {\ttfamily q9\+\_\+22\+\_\+t x = F\+M\+U\+L\+G( a, b, 28, 22, 22);}).
\item Integer overflow/underflow is M\+U\+CH easier to fall into with fixed-\/point numbers, since you\textquotesingle{}re often sizing them to be only exactly as big as you need them, forgetting that multiply/add and divide/subtract operations might cause these integers to exceed their maximum or minimum values. We saw an example of this above, in which the input values for our sin L\+U\+Ts needed to extend up to at least 403 in order to match our array indices, even though the input values should only ever really be as high as 2$\ast$\+PI. Addtionally, the fixed-\/point library at the link above performs all multiplication and divisions B\+E\+F\+O\+RE shifting the result up or down to match the final radix, meaning that even though a result might fit into the fixed-\/point data type to which an operation is being assigned, the operation may still fail if the intermediary product/sum/dividend/difference is greater than the maximum integer value (or less than the minimum value). This is actually a problem for our application, since even though the y-\/values in our sin table are in q0.\+31 format and multiplying them by any other number should yield a result that fits into the other number, because they are integers, the intermediary product may be as large as 64 bits, causing an incorrect value to get returned from the operation! To correct this, I added the {\ttfamily S\+A\+F\+E\+\_\+} functions to {\ttfamily fixed\+\_\+point.\+h}. These functions store the 32-\/bit operands into 64-\/bit integers before executing the desired operation; if the result is less than I\+N\+T32\+\_\+\+M\+AX (or greater than I\+N\+T32\+\_\+\+M\+IN), then the result is stored in the output variable and a value of {\ttfamily 0} (meaning \char`\"{}no error\char`\"{}) is returned from the function. However, if the safety check fails, then no value is stored and a {\ttfamily -\/1} is returned. The L\+UT code checks this value to make sure no math operations inadvertently overflowed or underflowed. I chose to {\ttfamily A\+S\+S\+E\+RT} that the error code returned is {\ttfamily 0}, since I figured that anything else constituted a programming error. However, it is possible to recover from a fault like that, and another developer may simply chose to retry the operation with a larger data type for the return variable.
\end{DoxyEnumerate}

The fixed-\/point L\+U\+Ts were significantly smaller and faster than either the double or float L\+U\+Ts, though at the cost of a fair bit of added complexity.

\subsubsection*{Adding linear interpolation}

So far our L\+U\+Ts have done nothing more complicated than map the input value onto the range \mbox{[}0, 403\mbox{]} and perform a simple rounding; a depiction of this type of L\+UT appears below. I\+M\+A\+GE A look-\/up table of this type will have a maximum error of E\+Q\+U\+A\+T\+I\+ON, which, for our sin L\+U\+Ts, comes out to around XX near the zero-\/crossing points and around XX near the local maxima and minima (to understand why, see \mbox{[}here\mbox{]}()). However, if we assume that each pair of adjacent elements in our L\+UT is connected with a line, we can get a much more accurate answer for input values that fall in-\/between the L\+UT elements by figuring out where on the line the input would fall and returning the resulting y-\/value. This is called \char`\"{}piecewise linear interpolation\char`\"{} (Pw\+LI) or, simply, \char`\"{}linear interpolation\char`\"{}. A depiction of this type of L\+UT appears below. I\+M\+A\+GE asdfasdf

\subsubsection*{Changing from a uniform to a non-\/uniform distribution of x-\/values}

\subsubsection*{Comparing to the polynomial approximations}